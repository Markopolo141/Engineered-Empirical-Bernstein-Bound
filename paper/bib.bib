% This file was created with JabRef 2.10.
% Encoding: UTF-8


@InProceedings{10.1007/978-3-540-75225-7_15,
  Title                    = {Tuning Bandit Algorithms in Stochastic Environments},
  Author                   = {Audibert, Jean-Yves and Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  Booktitle                = {Algorithmic Learning Theory},
  Year                     = {2007},

  Address                  = {Berlin, Heidelberg},
  Editor                   = {Hutter, Marcus
and Servedio, Rocco A.
and Takimoto, Eiji},
  Pages                    = {150--165},
  Publisher                = {Springer Berlin Heidelberg},

  Abstract                 = {Algorithms based on upper-confidence bounds for balancing exploration and exploitation are gaining popularity since they are easy to implement, efficient and effective. In this paper we consider a variant of the basic algorithm for the stochastic, multi-armed bandit problem that takes into account the empirical variance of the different arms. In earlier experimental works, such algorithms were found to outperform the competing algorithms. The purpose of this paper is to provide a theoretical explanation of these findings and provide theoretical guidelines for the tuning of the parameters of these algorithms. For this we analyze the expected regret and for the first time the concentration of the regret. The analysis of the expected regret shows that variance estimates can be especially advantageous when the payoffs of suboptimal arms have low variance. The risk analysis, rather unexpectedly, reveals that except for some very special bandit problems, the regret, for upper confidence bounds based algorithms with standard bias sequences, concentrates only at a polynomial rate. Hence, although these algorithms achieve logarithmic expected regret rates, they seem less attractive when the risk of suffering much worse than logarithmic regret is also taken into account.},
  ISBN                     = {978-3-540-75225-7}
}

@Article{10.2307/2282438,
  Title                    = {Probability Inequalities for the Sum of Independent Random Variables},
  Author                   = {George Bennett},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1962},
  Number                   = {297},
  Pages                    = {33--45},
  Volume                   = {57},

  Abstract                 = {This paper proves a number of inequalities which improve on existing upper limits to the probability distribution of the sum of independent random variables. The inequalities presented require knowledge only of the variance of the sum and the means and bounds of the component random variables. They are applicable when the number of component random variables is small and/or have different distributions. Figures show the improvement on existing inequalities.},
  ISSN                     = {01621459},
  Publisher                = {[American Statistical Association, Taylor \& Francis, Ltd.]},
  Url                      = {http://www.jstor.org/stable/2282438}
}

@Article{Bentkus08boundsfor,
  Title                    = {Bounds for tail probabilities of martingales using skewness and kurtosis},
  Author                   = {Vidmantas Bentkus and Tomas ju\v{s}kevi\v{c}ius},
  Journal                  = {Lithuanian Mathematical Journal},
  Year                     = {2008},
  Number                   = {1},
  Pages                    = {30--37},
  Volume                   = {48}
}

@Book{MR3363542,
  Title                    = {Concentration inequalities for sums and martingales},
  Author                   = {Bernard Bercu and Bernard Delyon and Emmanuel Rio},
  Publisher                = {Springer, Cham},
  Year                     = {2015},
  Series                   = {SpringerBriefs in Mathematics},

  Doi                      = {10.1007/978-3-319-22099-4},
  ISBN                     = {978-3-319-22098-7; 978-3-319-22099-4},
  Mrreviewer               = {Jean-Ren\'e Chazottes},
  Pages                    = {x+120},
  Url                      = {https://doi.org/10.1007/978-3-319-22099-4}
}

@Article{burnstein1,
  Title                    = {On a modification of Chebyshev’s inequality and of the error formula of Laplace},
  Author                   = {Sergei Natanovich Bernstein},
  Journal                  = {Uchenye Zapiski Nauch.-Issled. Kaf. Ukraine, Sect. Math},
  Year                     = {1924},
  Pages                    = {38--48},
  Volume                   = {1},

  Owner                    = {bur471},
  Timestamp                = {2018.08.14}
}

@Article{8000571,
  Title                    = {A Novel Online and Non-Parametric Approach for Drift Detection in Big Data},
  Author                   = {Moinak Bhaduri and Justin Zhan and Carter Chiu and Felix Zhan},
  Journal                  = {IEEE Access},
  Year                     = {2017},
  Pages                    = {15883-15892},
  Volume                   = {5},

  Doi                      = {10.1109/ACCESS.2017.2735378},
  ISSN                     = {2169-3536},
  Keywords                 = {nonparametric approach;drift detection;Big Data;Bernstein inequality;beta analysis;logitnormal analysis;data analysis;Electronic mail;Testing;Random variables;Monitoring;Big Data;Tools;Analytical models;Change point detection;non-parametric methods;Hoeffding’s inequality;Bernstein’s inequality;big data;anomaly detection}
}

@Article{Chebyshev1,
  Title                    = {Considérations àl'appui de la découverte de Laplace},
  Author                   = {Irénée-Jules Bienaymé},
  Journal                  = {Comptes Rendus de l'Académie des Sciences},
  Year                     = {1853},
  Pages                    = {309--324},
  Volume                   = {37},

  Owner                    = {bur471},
  Timestamp                = {2018.08.14}
}

@Article{Boucheron_concentrationinequalities,
  Title                    = {Concentration inequalities using the entropy method},
  Author                   = {Stephane Boucheron and Gábor Lugosi and Pascal Massart},
  Journal                  = {The Annals of Probability},
  Year                     = {2003},
  Number                   = {3},
  Pages                    = {1583-1614},
  Volume                   = {31}
}

@InBook{Boucheron2004,
  Title                    = {Concentration Inequalities},
  Author                   = {St{\'e}phane Boucheron and G{\'a}bor Lugosi and Olivier Bousquet},
  Editor                   = {Olivier Bousquet and Ulrike von Luxburg and Gunnar R{\"a}tsch},
  Pages                    = {208--240},
  Publisher                = {Springer Berlin Heidelberg},
  Year                     = {2004},

  Address                  = {Berlin, Heidelberg},

  Abstract                 = {Concentration inequalities deal with deviations of functions of independent random variables from their expectation. In the last decade new tools have been introduced making it possible to establish simple and powerful inequalities. These inequalities are at the heart of the mathematical analysis of various problems in machine learning and made it possible to derive new efficient algorithms. This text attempts to summarize some of the basic tools.},
  Booktitle                = {Advanced Lectures on Machine Learning: ML Summer Schools 2003, Canberra, Australia, February 2 - 14, 2003, T{\"u}bingen, Germany, August 4 - 16, 2003, Revised Lectures},
  Doi                      = {10.1007/978-3-540-28650-9_9},
  ISBN                     = {978-3-540-28650-9},
  Url                      = {https://doi.org/10.1007/978-3-540-28650-9_9}
}

@InProceedings{Carpentier:2011:UAA:2050345.2050366,
  Title                    = {Upper-confidence-bound Algorithms for Active Learning in Multi-armed Bandits},
  Author                   = {Alexandra Carpentier and Alessandro Lazaric and Mohammad Ghavamzadeh and R{\'e}mi Munos and Peter Auer},
  Booktitle                = {Proceedings of the 22nd International Conference on Algorithmic Learning Theory},
  Year                     = {2011},

  Address                  = {Berlin, Heidelberg},
  Pages                    = {189--203},
  Publisher                = {Springer-Verlag},
  Series                   = {ALT'11},

  Acmid                    = {2050366},
  ISBN                     = {978-3-642-24411-7},
  Location                 = {Espoo, Finland},
  Numpages                 = {15},
  Url                      = {http://dl.acm.org/citation.cfm?id=2050345.2050366}
}

@Article{Chung_concentrationinequalities,
  Title                    = {Concentration inequalities and martingale inequalities – a survey},
  Author                   = {Fan Chung and Linyuan Lu},
  Journal                  = {Internet Math},
  Number                   = {1},
  Pages                    = {79-127},
  Volume                   = {3}
}

@Article{efron1981,
  Title                    = {The Jackknife Estimate of Variance},
  Author                   = {Bradley Efron and Charles Stein},
  Journal                  = {Annals of Statistics},
  Year                     = {1981},

  Month                    = {05},
  Number                   = {3},
  Pages                    = {586--596},
  Volume                   = {9},

  Doi                      = {10.1214/aos/1176345462},
  Fjournal                 = {The Annals of Statistics},
  Publisher                = {The Institute of Mathematical Statistics},
  Url                      = {https://doi.org/10.1214/aos/1176345462}
}

@Article{hoeffding1,
  Title                    = {Probability Inequalities for Sums of Bounded Random Variables},
  Author                   = {Wassily Hoeffding},
  Journal                  = {Journal of the American Statistical Association},
  Year                     = {1963},

  Month                    = {Mar},
  Number                   = {301},
  Pages                    = {13--30},
  Volume                   = {58},

  Owner                    = {bur471},
  Timestamp                = {2018.05.19}
}

@InBook{Maron1997,
  Title                    = {Lazy Learning},
  Author                   = {Oden Maron and Andrew Moore},
  Chapter                  = {The Racing Algorithm: Model Selection for Lazy Learners},
  Editor                   = {David W. Aha},
  Pages                    = {193--225},
  Publisher                = {Springer Netherlands},
  Year                     = {1997},

  Address                  = {Dordrecht},

  Abstract                 = {Given a set of models and some training data, we would like to find the model that best describes the data. Finding the model with the lowest generalization error is a computationally expensive process, especially if the number of testing points is high or if the number of models is large. Optimization techniques such as hill climbing or genetic algorithms are helpful but can end up with a model that is arbitrarily worse than the best one or cannot be used because there is no distance metric on the space of discrete models. In this paper we develop a technique called ``racing'' that tests the set of models in parallel, quickly discards those models that are clearly inferior and concentrates the computational effort on differentiating among the better models. Racing is especially suitable for selecting among lazy learners since training requires negligible expense, and incremental testing using leave-one-out cross validation is efficient. We use racing to select among various lazy learning algorithms and to find relevant features in applications ranging from robot juggling to lesion detection in MRI scans.},
  Booktitle                = {Lazy Learning},
  Doi                      = {10.1007/978-94-017-2053-3_8},
  ISBN                     = {978-94-017-2053-3},
  Url                      = {https://doi.org/10.1007/978-94-017-2053-3_8}
}

@Article{Maurer_concentrationinequalities,
  Title                    = {Concentration inequalities for functions of independent variables},
  Author                   = {Andreas Maurer},
  Journal                  = {Random Structures and Algorithms},
  Year                     = {2006}
}

@Article{MR2245497,
  Title                    = {Concentration inequalities for functions of independent variables},
  Author                   = {Andreas Maurer},
  Journal                  = {Random Structures Algorithms},
  Year                     = {2006},
  Number                   = {2},
  Pages                    = {121--138},
  Volume                   = {29},

  Doi                      = {10.1002/rsa.20105},
  Fjournal                 = {Random Structures \& Algorithms},
  ISSN                     = {1042-9832},
  Mrclass                  = {60E15 (60C05)},
  Mrreviewer               = {Deli Li},
  Url                      = {https://doi.org/10.1002/rsa.20105}
}

@Misc{Maurer50empiricalbernstein,
  Title                    = {Empirical Bernstein Bounds and Sample Variance Penalization. stat},

  Author                   = {Andreas Maurer and Massimiliano Pontil},
  HowPublished             = {COLT},
  Month                    = {June},
  Year                     = {2009}
}

@InProceedings{Mnih:2008:EBS:1390156.1390241,
  Title                    = {Empirical Bernstein Stopping},
  Author                   = {Volodymyr Mnih and Csaba Szepesv\'{a}ri and Jean-Yves Audibert},
  Booktitle                = {Proceedings of the 25th International Conference on Machine Learning},
  Year                     = {2008},

  Address                  = {New York, NY, USA},
  Pages                    = {672--679},
  Publisher                = {ACM},
  Series                   = {ICML '08},

  Acmid                    = {1390241},
  Doi                      = {10.1145/1390156.1390241},
  ISBN                     = {978-1-60558-205-4},
  Location                 = {Helsinki, Finland},
  Numpages                 = {8},
  Url                      = {http://doi.acm.org/10.1145/1390156.1390241}
}

@Article{hoeffding2,
  Title                    = {{On the Bernstein-Hoeffding method}},
  Author                   = {Christos Pelekis and Jan Ramon and Yuyi Wang},
  Journal                  = {ArXiv e-prints},
  Year                     = {2015},

  Month                    = {Mar},

  Keywords                 = {Mathematics - Probability, 60E15, 60G50}
}

@Article{Pinelis2014,
  Title                    = {On the Bennett-Hoeffding inequality},
  Author                   = {Iosif Pinelis},
  Journal                  = {Annales de i'Institut Henri Poincar\'{e} - Probabilit\'{e}s et Statistiques},
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {15-27},
  Volume                   = {50},

  Abstract                 = {The well-known Bennett–Hoeffding bound for sums of independent random variables is refined, by taking into account positive-part third moments, and at that significantly improved by using, instead of the class of all increasing exponential functions, a much larger class of generalized moment functions. The resulting bounds have certain optimality properties. The results can be extended in a standard manner to (the maximal functions of) (super)martingales. The proof of the main result relies on an apparently new method that may be referred to as infinitesimal spin-off. Parts of the proof also use the method of certificates of positivity in real algebraic geometry.},
  Keywords                 = {probability inequalities; sums of independent random variables; martingales; supermartingales; upper bounds; generalized moments; Lévy processes; certificates of positivity; real algebraic geometry},
  Language                 = {eng},
  Publisher                = {Gauthier-Villars},
  Url                      = {http://eudml.org/doc/271996}
}

@Article{Zia-UrRehman2012,
  Title                    = {Exploiting empirical variance for data stream classification},
  Author                   = {Muhammad Zia-ur Rehman and Tian-rui Li and Tao Li},
  Journal                  = {Journal of Shanghai Jiaotong University (Science)},
  Year                     = {2012},

  Month                    = {Apr},
  Number                   = {2},
  Pages                    = {245--250},
  Volume                   = {17},

  Abstract                 = {Classification, using the decision tree algorithm, is a widely studied problem in data streams. The challenge is when to split a decision node into multiple leaves. Concentration inequalities, that exploit variance information such as Bernstein's and Bennett's inequalities, are often substantially strict as compared with Hoeffding's bound which disregards variance. Many machine learning algorithms for stream classification such as very fast decision tree (VFDT) learner, AdaBoost and support vector machines (SVMs), use the Hoeffding's bound as a performance guarantee. In this paper, we propose a new algorithm based on the recently proposed empirical Bernstein's bound to achieve a better probabilistic bound on the accuracy of the decision tree. Experimental results on four synthetic and two real world data sets demonstrate the performance gain of our proposed technique.},
  Day                      = {01},
  Doi                      = {10.1007/s12204-012-1261-5},
  ISSN                     = {1995-8188},
  Url                      = {https://doi.org/10.1007/s12204-012-1261-5}
}

@Article{zbMATH05780164,
  Title                    = {{Some better bounds on the variance with applications.}},
  Author                   = {Rajesh Sharma and Madhu Gupta and G. Kapoor},
  Journal                  = {Journal of Mathematical Inequalities},
  Year                     = {2010},
  Number                   = {3},
  Pages                    = {355--363},
  Volume                   = {4},

  Doi                      = {10.7153/jmi-04-32},
  Fjournal                 = {{Journal of Mathematical Inequalities}},
  ISSN                     = {1846-579X; 1848-9575/e},
  Language                 = {English},
  Msc2010                  = {60E15 15A42},
  Publisher                = {ELEMENT, Zagreb},
  Zbl                      = {1196.60030}
}

@Article{Talagrand1995,
  Title                    = {Concentration of measure and isoperimetric inequalities in product spaces},
  Author                   = {Michel Talagrand},
  Journal                  = {Publications Math{\'e}matiques de l'Institut des Hautes {\'E}tudes Scientifiques},
  Year                     = {1995},

  Month                    = {Dec},
  Number                   = {1},
  Pages                    = {73--205},
  Volume                   = {81},

  Abstract                 = {The concentration of measure phenomenon in product spaces roughly states that, if a set A in a product $\Omega$N of probability spaces has measure at least one half, ``most'' of the points of $\Omega$n are ``close'' to A. We proceed to a systematic exploration of this phenomenon. The meaning of the word ``most'' is made rigorous by isoperimetrictype inequalities that bound the measure of the exceptional sets. The meaning of the work ``close'' is defined in three main ways, each of them giving rise to related, but different inequalities. The inequalities are all proved through a common scheme of proof. Remarkably, this simple approach not only yields qualitatively optimal results, but, in many cases, captures near optimal numerical constants. A large number of applications are given, in particular to Percolation, Geometric Probability, Probability in Banach Spaces, to demonstrate in concrete situations the extremely wide range of application of the abstract tools.},
  Day                      = {01},
  Doi                      = {10.1007/BF02699376},
  ISSN                     = {1618-1913},
  Url                      = {https://doi.org/10.1007/BF02699376}
}

@Article{zbMATH00812598,
  Title                    = {{The missing factor in Hoeffding's inequalities.}},
  Author                   = {Michel Talagrand},
  Journal                  = {Annales de l'Institut Henri Poincare, Probability and Statistics},
  Year                     = {1995},
  Number                   = {4},
  Pages                    = {689--702},
  Volume                   = {31},

  Fjournal                 = {{Annales de l'Institut Henri Poincar\'e. Probabilit\'es et Statistiques}},
  ISSN                     = {0246-0203},
  Language                 = {English},
  Msc2010                  = {60E15 60G50 60F10},
  Publisher                = {Association des Publications de l'Institut Henri Poincar\'e, Paris; Institut of Mathematical Statistics (IMS), Bethesda MD},
  Zbl                      = {0837.60016}
}

@InProceedings{DBLP:conf/aaai/ThomasTG15,
  Title                    = {High-Confidence Off-Policy Evaluation},
  Author                   = {Philip S. Thomas and Georgios Theocharous and Mohammad Ghavamzadeh},
  Booktitle                = {Proceedings of the Twenty-Ninth {AAAI} Conference on Artificial Intelligence,
 January 25-30, 2015, Austin, Texas, {USA.}},
  Year                     = {2015},
  Pages                    = {3000--3006},

  Bibsource                = {dblp computer science bibliography, https://dblp.org},
  Biburl                   = {https://dblp.org/rec/bib/conf/aaai/ThomasTG15},
  Timestamp                = {Sun, 12 Apr 2015 15:18:08 +0200},
  Url                      = {http://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/10042}
}

